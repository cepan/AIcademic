{
    "0-20": " we're now going to take an entirely different approach the problem of finding similar sets of items without looking at all pairs of sets these methods are suitable when we're looking for sets at a very high Jaccard similarity or low Jaccard distance roughly these work well compared with the LSH technique studied so far if the threshold for similarity is 80% or more",
    "20-40": " an advantage to these methods is that they are exact there are no false negatives although they still have false positives that need to be compared the methods we discuss involve creating an index of sets which is not too different from hashing sets the buckets however the indexes exploit a number of tricks",
    "40-60": " we sort the elements in each set and think of sets as strings when we're looking for very high similarity of the lengths of these strings tells us a lot since the similar sets cannot have strings whose lengths are too different we shall also use tricks based on the prefixes and suffixes of the strings to",
    "60-80": " set the stage we're back to talking about sets and their Jaccard distance recall that jacquard distance is 1 minus the Jaccard similarity and Jaccard similarity of two sets is the size of their intersection divided by the size of their union our first step is to",
    "80-100": " represent sets by strings the characters of the string are the elements of the set in order that is we pick an order for the elements of the Universal set for any set we can sort its elements according to this order the string representing a set is the list of these",
    "100-120": " elements in the sorted order a special property of these strings is that no character that is set element appears twice in the string let's consider the example of sets of k shingles that is the universal set is the set of k shingles and the shingles being",
    "120-140": " character strings can be ordered lexicographically so that there is the ordering of the universal set that we need we have to make a little mental leap however at one level shingles are themselves characters but we have to think of each shingle as a single character in a larger alphabet we don't have a way to invent characters for each of these shingles so we need to",
    "140-160": " represent those characters with what looked like strings of length K so let's take a particular example we'll use K equals 2 and the document we shingle will be ABC ad the four shingles in this document are a B BC C a and AD let's",
    "160-180": " sort these shingles lexicographically first is a B then comes a D finally BC",
    "180-200": " and then CA the sorted list of shingles is thus a B ad BC and CA again understand that a B and similar strings are ways we are expressing single",
    "200-220": " characters in the string of four characters so this is really a single symbol that's a symbol that's a symbol and that's a symbol and we're representing strings as lists of these characters here to make the separation between characters clear",
    "220-240": " let's see another example based on documents we could represent a document by its set of words this would be appropriate if we were looking for similarity based on topic rather than character by character similarity even the words are of different lengths while shingles are all of the same length we can still use lexicographic order that",
    "240-260": " is dictionary order to sort the universal set of words the fact that here the universal set is independent doesn't matter because we can still tell the order of any two words and that is all we need to sort the finite sets of words that come from documents however there is a better way to order words for the application we have in mind",
    "260-280": " count the occurrences of the words in our collection of documents and then order the words rarest word first you can break ties lexicographically the reason for putting the words with the lowest number of occurrences first is that when we index the strings that represent documents we shall base the index on the first characters in these",
    "280-300": " strings the characters of these strings are actually words of the documents so we are indexing documents in such a way that two documents will fall into the same bucket only if they have a very rare word in common we want to have many buckets and very few strings in each bucket incidentally we're talking about strings in a confusing way so let's sort",
    "300-320": " things out a bit documents are strings of characters like there's ABC blanks maybe we bust the documents into words the dog we think of the documents as",
    "320-340": " it's said of words so is that the dog and we then create from these sets new strings whose characters are the words in order of fewest occurrences first so",
    "340-360": " we might have for example dog the and so on I'm assuming that dog is a rarer word than V it probably is and it is these strings or these objects",
    "360-380": " characters like dog and the four which will create the indexes since we've converted sets into special kinds of strings it is useful to start out understanding the relationship between the jacquard distance of the sets and the Edit distance of the strings so",
    "380-400": " suppose the jacquard distance of two sets is j these sets are represented by strings s 1 and s 2 and let the least common subsequence of these strings be of length C and then let the Edit distance between them be e we claim that",
    "400-420": " 1 minus J and that is the Jaccard similarity of the underlying sets is C divided by c plus e that is the size of the intersection of the sets of c and the size of the union is c plus e to c y notice string s 1 has certain characters that s 2 does not have and vice versa",
    "420-440": " the only way to convert s 1 into S 2 is to delete the characters s 1 has that as 2 doesn't have and then to insert the characters that s 2 has but as one doesn't the union of the underlying sets is all the symbols in the LCS of s 1 and s 2 plus the symbols and s 1 but not",
    "440-460": " nest 2 plus those in s 2 but not in s 1 thus the size of the union is C plus the edit distance we should comment that this method of trying to convert s 1 to s 2 doesn't work in general but it works here because the symbols they have in",
    "460-480": " common appear only once and they appear in the same order thus the only LCS for s 1 and s 2 is their entire list of common symbols and finally we can reorganize the equation above that one - jake will c over c plus e to get j the jacquard distance of sets is e over",
    "480-500": " plus e we're going to go through a series of progressively more complicated forms of indexes to put on the strings to grab that represent the sets our first and simplest approach is to index by length of the string only that",
    "500-520": " corresponds to indexing sets by their size there's an important relationship between Jaccard distance and length of the strings that represent sets if a set has size L so it's string has length L then the set can be Jaccard distance j from a set of size m only if m lies",
    "520-540": " between L times 1 minus J and L divided by 1 minus J will justify this relationship on the next slide but for example if J is 0.1 that is the Jaccard",
    "540-560": " similarity 1 minus J of the underlying sets is at least 90% then M must be in the range point 9 L and 1 point 1 1 L or put another way M must be at least 90 percent of L and L must be at least 90 percent of M here's why the relationship",
    "560-580": " between L and M must hold first given L how short could the other string be and still have Jaccard similarity at least 1 minus J to maximize the Jaccard similarity we have to assume that the set of size M is a subset of the set of",
    "580-600": " size L then the intersection of the sets of size M and the union has size L that is the Jaccard similarity is M over L and therefore M is L times 1 minus J",
    "600-620": " now consider the case where m is the size of the largest set that could be at your car distance J from the set of size L here we must have the set of size L contained in the larger set their intersection of size L and the Union s size M that means that your card similarity is L over m and M is L",
    "620-640": " divided by 1 minus J if you don't know what B trees are it doesn't matter that much but let me point out that B trees are great for finding keys with any given range so if we index strings using",
    "640-660": " their lengths as the index key we can find given a length L all strings whose lengths are in the range L times 1 minus j2 L over 1 minus J without having to look at any strings whose length is outside that range that gives us candidate pairs of strings however just",
    "660-680": " because two strings have similar lengths doesn't mean they have higher card similarity they could have completely different members thus we need to compute the actual Jaccard similarity of every pair of strings of similar length by the way I have started talking about the Jaccard similarity of strings when what I really mean is the Jaccard similarity of the sets that the strings",
    "680-700": " represent I'm going to use that shorthand in the future and I trust that there will be no confusion"
}