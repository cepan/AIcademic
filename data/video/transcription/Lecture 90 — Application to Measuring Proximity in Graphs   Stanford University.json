{
    "0-20": " the next example of PageRank that we will look at is the application to measuring proximity in graphs so here is basically the idea imagine and we are given a graph and we would like to measure some notion of proximity or closeness or similarity between nodes a and B so the red node the hexagonal node a and the kinks agonal node B and the",
    "20-40": " question is how do we how do we do this one way how to do this would be to use the shortest shortest paths so the problem is short as pets is that for example in these two different cases the shortest path computation would give me the same value the distance between nodes a a and B is the same even though kind of in the second case we could say",
    "40-60": " because of all these dangling nodes the the proximity between a and B is smaller than than in the first case another thing for example that happens when we are using shortest paths to measure proximity of nodes in a graph is that if there are multiple separate paths between a pair of nodes we don't really",
    "60-80": " care about that even though for example here in the first case intuitively we would like nodes a and B to be closer to each other than then in the second case because in the second case there is only one path but in the first path case we have two different paths connecting a and B so for example shortest path length between a pair of nodes may not be the best notion of proximity um",
    "80-100": " another thing we could we could do is for example to say how much flow how much network flow can be pushed between nodes a and B the the problem is that even this is not to good solution to intuitively capture the notion of similarity or proximity of nodes in a graph the problem is here that we can",
    "100-120": " have very long chains and they don't get penalized right so in the case I have here both nodes a and B we are able to push one unit of flow between them even though in the first case we would we would intuitively say that nodes a and B are closer or more their proximity is better than in the second case so the",
    "120-140": " problem if Network closed is that it doesn't capture long paths so the question is what is a good notion of proximity and if you think about the good notion of proximity it would be a metric that would consider that there are multi always to get from one node to another right so that there are multiple pets and another one is that it would also consider the quality or the weight of",
    "140-160": " connections in terms of whether the connections are directed or not whether how long are these connections how strong they are what is the degree of the node and so on and as it turns out a good way to make to measure proximity in a graph is called a method is called simmering and symlink is basically a random walk with three starts from a",
    "160-180": " single fixed node right and what is interesting is that sim rank was initially proposed where we have this what is called caper types graphs where the idea is that we have different types of entities imagine we have K different types of entities and now we create an caper type graph where basically entities of one type are linking only to",
    "180-200": " the entities of another type so for example we could create a graph where we have two partitions one is a set of all the images and the other one is a set of all the tags between between the images and now one the idea is how do we measure similarity between a pair of images and one way to measure similarity between a pair of images is to basically",
    "200-220": " do a random walk of restarts from one page to and measure the proximity to every other page this is what I mean by random walk with lists of v3 starts is simply the personalized PageRank where where the teleports set s is a single node which is the starting node news this basically means that the random Walker can walk around the graph but",
    "220-240": " then always jumps back to our starting node U so this means that this the the resulting page rank scores will measure the proximity or similarity of any other node in the graph with respect to the no deal of course the problem with this is that this is not the most scalable method because that because it means",
    "240-260": " that for every node we have to compute a separate set of similarities so this is something that works well for kind of sub web-scale problems but on a larger web scale graph this may be too hard to do and we want to we don't want to have the teleport set to be individual nodes but may be sets of nodes and then we are back to the personalized spending world",
    "260-280": " that we talked about today just to show you an example of how this can be done is imagine you want to similarities between different conferences and you would for example like to know what are the most in similar conferences to the conference of ICD M ICD M is a data mining copied conference very well known so one way to measure these similarities would be the",
    "280-300": " following we would first create the bipartite graph of conferences and the authors that publish on these conferences right so every note here is a different computer science conference and every note on the right is a different author a different scientist and we connect a given author and a",
    "300-320": " given conference if that author published the paper at that conference what we do now for example is we perform now a random walk with three starts from the node icbm and measure what the visiting probability of the random walker of all other nodes on my left partition and what what will happen is",
    "320-340": " that we will basically obtain different scores of the nodes on the left the idea here is write the two conferences will be close if they share lots of co-authors in common if there is many shorter spans between them and so on right so if we actually do this and measure and ask what is the result we get for example here is my ICD M",
    "340-360": " conference and here is a list of conferences that are most similar to it here are the corresponding random walk with restart scores and we see the kennedys so the International Conference on data mining is the most is the most similar and then another data mining conference and another data mining conference the pig-headed is the European version",
    "360-380": " Pik DD specific Asia conference conference on data mining and then its conference on machine learning and databases and so on and so forth right so we get very intuitive results but basically running the person is paging on on this bipartite graph in this idea can very naturally be extended to other",
    "380-400": " types of graphs and other types of entities"
}