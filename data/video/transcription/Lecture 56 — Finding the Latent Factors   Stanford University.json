{
    "0-20": " so what we will learn next is how to actually find the latent factors or in other words how to solve our um optimization problem so the thing we want to do is the following right we we are given the Matrix R we want to represent it as a product of matrices uh q and P the way we want to find matrices",
    "20-40": " q and P is in a such a way that it best predicts the known ratings right so what we want to do is we want to um solve the following optimization problem right we want to find u p and Q in such a way that the the predicted ratings are as close to True ratings as possible now um",
    "40-60": " the idea is right we want to minimize the sum of squared errors which basically means we want to minimize the root mean square error for unknown unseen data because we cannot do this we will we will minimize the sum of squared errors on the training data so I can think of this I that I have a function that is depends on matri speed p and Q",
    "60-80": " and I want to find those matrices such that the predicted ratings are as close to the true ones as possible so now um how do I go and find U the minimum of such an such an error function whenever we are given a a nice function that we can take derivatives of the method that immediately comes to mind is called um",
    "80-100": " gradient descent right so basically the idea is that we if we have a simple function just kind of very abstractly now that that is the depend on some variables or on a variable X then the idea is basically we want to compute the derivative of that function evaluate the derivative of the function at a given",
    "100-120": " point and then move in the direction the opposite of the derivative or the gradient right so the idea is basically if I if I have some um some function f that has some given um shape and I want to find the uh the minimum of this function I would start at some arbitrary random point let's call it y I would",
    "120-140": " evaluate the gradient at that point Y that basically means that I would compute what is the slope of that function at that given point and then I would make a small step in the reverse direction of the slope and that would give me kind of would get me closer to the minimum in the next step I would go reevaluate the gradient um this is how",
    "140-160": " it would that's how the the slope of the of the line would be and I would again make a small step in the reverse direction of the gradient and I would keep doing this until I would get stuck right until kind of I I reach the minimum of the function so this is basically the strategy we'll be using to solve our our optimization problem right",
    "160-180": " we already have the the uh equation we can simply take the derivative this is a simple kind of quadratic equation so taking derivative is very easy um and we can code up our optimization algorithm in like 10 lines of code so everything seems to be very straightforward and easy however there is one um critical",
    "180-200": " component that we will have to add in order for our uh recommender system to work right so we are saying let's minimize the sum of squared errors on uh the training data and here the idea is right that kind of we want to pick the number of factors K to be to be some number uh and to be enough to capture",
    "200-220": " kind of all all the signal imagine we pick K of 100 if we do this and and observe for example measure what is the sum of squared errors on unseen test data we actually find that as soon as we pick more than two factors our error on the Unseen data increases with the number of",
    "220-240": " factors we are picking right so just let's just say it again so basically what it seems is that as soon as we are making our model too strong our model stops working right our um sum of squares errors on the UN unseen test data starts increasing and in machine learning this",
    "240-260": " kind of phenomena is called overfitting and basically the the way what overfitting means is that the the model is is adapting itself too much to the training data and the model is basically has too many free parameters those free parameters starts to fit noise and the model has trouble to generalize to the",
    "260-280": " Unseen uh test data right so the problem is that the model is overfitting too much on the training data and doesn't generalize to the Unseen data so it's seems like a very hard to solve problem right we have a very complex model we feed this complex model to the data the the model the model has so many degrees of freedom that it's very easy for it to",
    "280-300": " start kind of fitting The Noise by fitting the noise the model loses the generalization um ability so the way we um um go around this problem is by modifying our optimization function and the particular technique will talk about how to remedy this problem is called",
    "300-320": " regularization and the idea with regularization is basically that we want our model to to have Rich structure right so kind of to spend lots of modeling power in the areas where we have sufficient data and then we kind of want our model to be very simple in the areas where we don't have enough data right so where kind of the evidence is",
    "320-340": " is sufficient for comp for complexity we want to use lots of modeling power but in the areas where we only see a few data points there we want to have the model to be as simple as possible so that we don't start kind of overfitting or fitting the noise the way we achieve this intuition is that we we have our",
    "340-360": " optimization problem now has two components we have our old part that we already know the one that I call the error which is simply how well are we fitting the training data but then we also have the second part that we call length Okay and we have this parameter Lambda that we we call the",
    "360-380": " regularization parameter and this is some non non- negative value that basically trades trades off between these two competing parts right the the training error and the length right and let's just think about what these two what these two pieces are doing right so if we would if we would really just care to minimize the training error then we",
    "380-400": " could set Lambda to zero the complexity of our model uh in the right wouldn't really matter and we would minimize the error for for example if we if we don't really care about making good predictions but we care our about our model to be very simple then we would set Lambda to be very high and all that",
    "400-420": " would basically force is that P and Q would be full of zeros and this way again we would reach the the the small value of the objective function of course where we want the Lambda to be is to be somewhere in between in some kind of just the sweet spot so now let me give you some intuition about what what is this L part uh doing to our",
    "420-440": " optimization problem and the way the way to think about our objective function is that it has two parts to the to the to it right there is the error part and there is this length part okay and think of it the following right think that I have that I have a user and the way we",
    "440-460": " can think about the following is that for this user we want to make accurate predictions using the ratings that the user has already made right so if this user has made lots and lots and lots of ratings then there are kind of two parts in this objective function that are trading off each other so one is that we want to make the error for this user to",
    "460-480": " be small and on the other hand we want the factors describing this user to be small and what does the factors to be small mean it basically means the distance of the user from the coordinate origin right so we are basically now trading off two things so if we have very little training data for the for",
    "480-500": " the user right if the usera rated very few movies then what will happen is that is this error part will go will have only a few movies in the summation so the value of the error part will be relatively small which means that what we will want to do for such a user we will want to also to make length small",
    "500-520": " because by making the length small will increase the will increase the error but because the error has only few terms that won't add add too much to the global error so what will happen is this this user will basically start moving more and more towards the coordinate origin on the other hand if we would have lots of training data for for our",
    "520-540": " user then we wouldn't really want to move the user towards the coordinate origin right we would we would we wouldn't want to make uh its latent factors too short because the the error term would have lots of terms so we would really want to make accurate predictions for all those terms and we would be tolerate kind of more complex",
    "540-560": " factors for that user right so in some sense this what what regularization is doing it's trading off between the performance predictive performance of the model versus the the complexity of the model okay so now basically all we have is we have already decided right we",
    "560-580": " have our optimization problem we want to find matrices p and Q where we want to minimize both the uh the accuracy of the model the the ability of the model to predict the ratings plus the Simplicity of the model and our parameter Lambda trades off between the Simplicity and uh the predictive",
    "580-600": " performance uh one thing to be to note in this formulation is that kind of we don't really care about the the absolute value of the objective function what we really care about is finding matrices p and Q that that minimize the that minimize that value and we are really want matrices p and Q that actually",
    "600-620": " predict well the Unseen uh ratings so we are never really kind of um want to really find or care about the value of the of the objective function we really care about what are the matrices that achieve that um value so now of course how do we go and",
    "620-640": " solve this objective function we are use we can use gradient descent the same way I as I demonstrated a few slides ago right so we have we have even though it looks very complicated we have a very simple function that we would like to optimize so the way we do is we we apply the gradient descent uh procedure where",
    "640-660": " for example imagine we initialize matrices p and Q simply using SVD and pretending that missing ratings are equal to zero that just kind of gives us a good in initialization point and then we we perform gradient descent which means which means we will repeat this two steps until we obtain convergence basically",
    "660-680": " until the gradients are very close to zero and the way this works is basically we will say whatever is our estimate of Matrix P at time T we will we will have small parameter um that we call the Learning grate times the gradient with respect to the parameters and that gives",
    "680-700": " us the value of Matrix P at time t plus one now that we have the the value of Matrix at time t+ one we can go to the second step here we take the value of Matrix Q at time t + 1 compute the gradient make the step and this gives us the Matrix U at time t + one and then we kind of go repeat to the first step of",
    "700-720": " course now how do we compute the gradient of a matrix um that is that is easy we just compute the gradient of the equation above so for example in our case I have I have a summation um so taking a derivative of summation is is easy I don't need to do anything then I have this quadratic function I take I",
    "720-740": " take the I take the derivative and then I also have this penalty term um because I'm taking the derivative for example here with respect to q p is just a constant so there is nothing to take uh for p and this is what happens for the derivative of Q and I could compute the derivative in a very simple way also with respect to P evaluate my derivative",
    "740-760": " over the training data um and make um make a step make a small step and keep doing this until we converge in this way we would solve the optimization problem um now for example if we actually go do this on the Netflix Challenge and obtain these latent factors we can ask what and",
    "760-780": " set for example k equals to that we only obtain two latent factors and then map movies into this latent space of of the two factors here is what we see for example we see that wizard of O is kind of in the center of this uh recommander system and then you know for example here are the kind of bloody movies and",
    "780-800": " um in this part we get we get some action movies and so on and so forth so you see that basically how the similar movies now get grouped together uh or in the similar Parts um of this abstract movie space"
}