{
    "0-20": " so in the last part of the lecture on recommender systems we will now see how we can combine latent vector models we also include the global effects that we talked about few videos ago right so the way we want to kind of model both the biases in interactions is in this kind of way right in some sense we would want",
    "20-40": " to model the user bias we would want to model the movie bias and then you also want to model the user movie interaction right and the way we can achieve this is very similar to what we already talked about right we can have to in order to model biases we need we need kind of three values we need the overall mean",
    "40-60": " rating of all the movies in our data set we need the bias of the user so how much does the user deviate on the average from the mean rating and how much does the movie deviate from the mean rating and then we will be using our latent factors to basically characterize the interaction between users and movies",
    "60-80": " okay and the way we can do this is basically we want to put everything together so this means that we will have an expectation on rating by user X of movie I even kind of without estimating X s attitude towards the movies that are similar to I so the idea is that I want",
    "80-100": " to have a rating scale for the user on X and I kind of also want to know some kind of popularity of movie I and I want to have some kind of bias factor for the movie and I want to also have some some factor for for the user so the way we can put everything together is the",
    "100-120": " following we say that our predicted rating for MU user X and movie I is the overall mean rating plus the bias for user X plus the bias for movie I plus the user movie interaction right so the way we would we would reason now about the recommendation we would say AHA the",
    "120-140": " mean rating is 3.7 you are a critical view err so your be X is minus 1 you are watching Star Wars which is a really good movie that is rated half a star above the average now my predicted rating for you based on these biases is 3.2 and then we also include the interaction term to further",
    "140-160": " up or down this rating of course now that we have these biases we can actually go and compute them using averages as we did before or we can actually include them as parameters into our optimization problem right so for example we could do the following we",
    "160-180": " could say we want to go and find P and Q in such a way that the Q rating of an item and the predicted rating of an item differ as little as possible where what are the things we want to estimate now is we want to estimate B of X B of Phi Q",
    "180-200": " of I and P of X right so now we just kind of added another another set of parameters to our models in some sense we want to estimate the bias for every user anyone to also estimate the bias for every movie so now our regularization term kind of expanded right we have the regularization over the the matrix factorization part but",
    "200-220": " then we also have the regularization term over the biases and the same way as we did before I can have now this kind of massive diffident I can take the derivative of it with respect to P with respect to Q with respect to B X and with respect to B I and I can do the gradient descent the same way as I did before and I estimate all these",
    "220-240": " parameters and of course it as it will turn out if we do this performance gets even better so here is a slide how well these things work so here I'm comparing for example collaborative filtering with the basic latent factors that we talked about in the previous video to end with latent factors that also include biases",
    "240-260": " and what I'm showing you here is root mean square error and here is the number of millions of parameters my model has okay and you see that for example as I increase the size of the neighborhood in the collaborative filtering I get from 0.9 1 all the way down to let's say almost like 0.9 while for example a",
    "260-280": " basically latent factors actually works better than commander systems and now if I also learn the biases basically advices as parameters that we want to estimate from data that gives me further improvement right and we are almost all the way down to 0.8 9 root mean square error one",
    "280-300": " thing to note here is that our model is very complex our model has basically 100 million parameters which is the same as the number of ratings we have right so it kind of seems crazy we have the same number of parameters then we have the data but because we are using this",
    "300-320": " regularization terms this penalty terms that we multiplied by lambda even though our model is so complex it has so many degrees of freedom the regularization effectively forces the model to be very wise where to kind of use complexity and where to use simplicity so what we know so far kind of going back to our chart on",
    "320-340": " performance of various methods we know that with kind of basic collaborative filtering we were at 0.94 with a bit more fancy collaborative filtering we were able to push this down to point nine one we saw that basic latent factors are at point point nine and latent factors including biases are at",
    "340-360": " point nine eight nine eight so kind of using clean methods this is as close as we can get to the to the grand-prize own of point eight error point eight five the question is how do we go and achieve this final gap okay and lots of work actually went in kind of closing this",
    "360-380": " last final gap before the 1 million dollar prize so here's the idea so one thing that we haven't yet used in in our model is the idea that ratings change over time so for example people analyze the data and noticed that for example if we plot time versus the average score of",
    "380-400": " a movie we see that this in in around 2000 for the ratings jumped for all more forward kind of discontinued discontinuous way another thing we also see is for example that the movies age",
    "400-420": " well sense that that us that us the time goes on the movies get get get higher and higher ratings in a sense that older movies get get rated higher as the time goes on so what this means is that we can now take our recommender system and kind of train a separate recommend recommender system",
    "420-440": " for every for every month right so for every separate month of our dataset we will train a separate recommender system so that this way we can also capture the time biases okay so what this means is the following with a simple latent recommender system including biases we were our error was",
    "440-460": " 0.98 by by adding also the time factors and you know time of day and things like that parameters we can get down to 0.75 so still still away from the from the grand-prize notice now that the number of parameters of these models is",
    "460-480": " ridiculous it's like it's a billion parameters which is huge it's kind of 10 times more than what we have data but still we are kind of disappointed we are not even close to the price so given that we are kind of not even close to the price then what do you do you kind of get desperate and you try a",
    "480-500": " kitchen sink approach which basically means you just throw everything together and you hope it will work so actually the winning solution what it did is that they came up with hundred and thirty different recommender systems and then they basically used when a user movie pair came they asked each of these 130",
    "500-520": " recommender systems to rate that that pair and then they blend that all these recommendations or these ratings into a single prediction so in some sense they took a linear combination of all these ratings think of it as an average and then they made a prediction and using using this they were actually able to achieve this magical ten percent",
    "520-540": " improvement right so if you look at the Netflix leaderboard in 2009 the the winning team that was from AT&T research or Bell Labs actually achieved that error and a few a few months later they actually received the check and took",
    "540-560": " this very nice photo so basically we saw that using very nice mathematically clean algorithms you can get very close to the grand prize but for the last two make the last few percent this kind of kitchen sink approach had to be had to be used to make the predictions but what industry is using today in practice are",
    "560-580": " these latent factory commander systems using the biases and using gradient descent or stochastic gradient descent to find the parameters of these models one has to be also very careful with the circularization otherwise this model stem to very heavily overfit"
}