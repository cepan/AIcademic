{
    "0-20": " welcome to mining of massive datasets i'm anand raj raman and today's topic is MapReduce in the last few years MapReduce has emerged as a leading paradigm for mining really massive datasets but before we get into MapReduce proper let's spend a few minutes trying to understand why we need MapReduce in the first place let's start with the basics now we're",
    "20-40": " all familiar with the basic computational model of CPU and memory right the algorithm runs on the CPU and accesses data that's in memory now we may need to read the data in from disk into memory but once the data is in memory it fits in there fully so you don't need to access disk again and the algorithm just runs in the data that's",
    "40-60": " on memory now this is a familiar model that we use to implement all kinds of algorithms and machine learning and statistics and pretty much everything else now what happens if the data is so big that it can't all fit in memory at the same time that's why a data mining comes in and classical data mining",
    "60-80": " algorithms look at the disk in addition to looking at CPU in memory so the data is on disk you can only bring in a portion of the data into memory at a time and you can process it in batches and you know right back partial results to disk and this is the realm of classical data mining algorithms but sometimes even this is not sufficient let's look at an example",
    "80-100": " so think about Google crawling and indexing the web right let's say Google has crawled 10 billion web pages and let's further say that the average size of a web page is 20 kilobytes now these are representative numbers from from",
    "100-120": " real life now if you take 10 billion web pages each of 20 kilobytes you have a total data set size of 200 terabytes now when you have 200 terabytes let us assume that we're using the classical computational model classical data mining model and all this data stored in a single disk and we have to read it tend to be processed inside a CPU now",
    "120-140": " the fundamental limitation here is the is the bandwidth the data bandwidth between the disk and the CPU the data has to be read from the disk into the CPU and the discrete bandwidth for most modern Saturdays representative number is around fifty megabytes a second so we can read data at fifty",
    "140-160": " megabytes a second how long does it take to read 200 terabytes at 50 megabytes a second can do some simple math and the answer is 4 million seconds which is more than 46 days remember this is an awfully long time and this is just a time to read the data into memory to do something useful with the data it's going to take even longer alright so clearly this is unacceptable",
    "160-180": " you can't take 4 to 6 days just to read the data so you need a better solution now the obvious thing that you think of is that if you can split the data into chunks and you can have multiple disks and CPUs you stripe the data across multiple disks and you can read it in and process it in parallel in multiple CPUs that's going to cut down this time",
    "180-200": " by a lot for example if you had a thousand disks and CPUs into the fourth hour 4 million seconds and we were completely in parallel in so 4 million seconds we could do the job in 4 million by thousand which is four thousand seconds and that's just about an hour which is which is a very acceptable time",
    "200-220": " right so this is the fundamental idea behind the idea of cluster computing right and this is the standard architecture that has emerged for cluster computing is something like this you have a rax consisting of commodity Linux nodes you go with commodity Linux nodes because they are very cheap and you can you can you can buy thousands",
    "220-240": " and thousands of them and interact them up you you have many of these racks each rack has 16 to 64 of these commodity Linux nodes and these nodes are connected by a switch and the switch in iraq is typically a gigabit switch so",
    "240-260": " there's a 1 gigabit per second bandwidth between any pair of nodes in a rack of course 16 to 64 nodes is not sufficient so you have multiple racks and all the racks themselves are connected by backbone switches and the backbone switch is a high bandwidth switch I can do 2 to 10 gigabits between racks right",
    "260-280": " so so you have 16 to 64 nodes in a rack and then you you of multiple racks and and you get a data center so this is the standard classical architecture that has emerged over the last few years for you know for storing and mining very large data sets now once",
    "280-300": " you have this kind of cluster that doesn't solve the problem completely because cluster computing comes with its own challenges but before we get there let's get us you know idea of the scale right in 2011 somebody estimated that Google had a million machine million nodes like this in stacked up you know",
    "300-320": " it is somewhat like this so so that gives you a sense of the scale of modern data centers and and then clusters right so here's here's a picture this is what it looks like inside a data center so the what you see there is the back of racks and you can see the connections between between the racks now once you",
    "320-340": " have the such a big cluster you actually have to do computations on the cluster right and cluster computing comes with its own challenges the first and most major challenge is that nodes can fail right now a single node doesn't fail",
    "340-360": " that often right if you if you just run a Linux node and let it stay up it can probably stay up for three years without failing three years is about a thousand days so that's you know once in a thousand days failure isn't such a big deal but now imagine that you have a thousand servers in a cluster and in you and if you assume that these servers",
    "360-380": " fail independent of each other up you're going to get approximately one failure a day which still isn't such a big deal you can probably deal with it but now imagine something on the scale of Google which has civilian service in its cluster so if you have a million servers you're going to get a thousand failures per day now a thousand failures per day is a lot and you need some kind of infrastructure to deal with that kind of",
    "380-400": " failure rate the failures on that scale introduce two kinds of problems the first problem is that if you know if nodes are going to fail and you're going to store your data on these nodes how do you keep the data and store it persistently what does this mean persistence means that once you store the data you open guaranteed that you can read it again but if the node on",
    "400-420": " which you store the data fails then you can't read the data you might even lose the data so how do you keep the data stored persistently if if these nodes can fail now the second problem is is is one of availability so let's say you're running one of these computations and this computation is you know analyzing massive amounts of data and it's",
    "420-440": " chugging through the computation and it's you know run halfway through the computation and you know at this critical point a couple of nodes failed right and that node had data that's necessary for the computation now how do you deal with this problem now in the worst case you may have to go back and restart the computation all over again but if you restart it now and then the",
    "440-460": " computation turns again and load may fail again when the computation is running so you kind of need an infrastructure that can hide these kinds of node failures and let the computation go to go to completion even if nodes fail the second challenge of cluster computing is that there's the",
    "460-480": " network itself can become a bottleneck now remember there is this one gigabit per second network bandwidth that's available between individual nodes in a rack and at a smaller bandwidth it's available between individual racks now if you have ten terabytes of data and you have to move it across one gigabit per second network connection that takes approximately they can do the math and",
    "480-500": " figure that out you know a complex computation might need to move a lot of data and that can slow the computation down so you need a framework that you know doesn't move data around so much while it's doing computation the third problem is the distributed programming can be really really hard even sophisticated programmers find it hard",
    "500-520": " to write distributed programs correctly and avoid race conditions and various kinds of complications so you need a simple problem that hides most of the complexity of distributed programming and and makes it easy to write in algorithm second mind radial massive data sets so you looked at three problems that you know that we faced",
    "520-540": " when we are dealing with cluster computing and MapReduce addresses all three of these challenges right first of all the first problem that we saw was that it was one persistence and availability if nodes can fail the map reduced model addresses this problem by storing data redundant ly on multiple nodes the same data is",
    "540-560": " stored on multiple nodes so that even if you lose one of those nodes the data is still available on another node the second problem that we saw was one of network bottlenecks and this happens when you move around data a lot what the MapReduce model does is that it moves the computation close to the data and avoids copying data around the network",
    "560-580": " and this minimizes a network bottleneck problem and thirdly the MapReduce model also provides a very simple programming model that hides the complexity of all the underlying magic so let's look at each of these pieces in turn the first piece is the redundant storage infrastructure now redundant storage is provided by what's called a distributed",
    "580-600": " file system a distributed file system is is a file system that stores data you know across a cluster but stores each piece of data multiple times so the distributed file system provides the global file namespace it provides redundancy and availability there are multiple implementations of distributed file systems Google ZFS is or Google",
    "600-620": " file system or GFS as one example Hadoop HDFS is another example and these are the two most popular distributed file systems out there a typical usage pattern that these distributed file systems are optimized for is huge files that are in the hundreds of gigabytes or",
    "620-640": " terabytes but the even though the files are really huge the data is very rarely updated in place right once once data is written you know it's read very often but when it's updated its updated through a pense it's never updated in place and for example let imagine the Google scenario once again when Google",
    "640-660": " encounters a new web page it adds the web page to its repository it doesn't ever go and update the content of a webpage that it already has crawled right so a typical usage pattern consists of writing the data once reading it multiple times and appending to it occasionally let's go into the hood of a distributed file system and",
    "660-680": " see how it actually works data is are kept in chunks that are spread across machines so if you take any file the file is divided into chunks and these chunks are spread across multiple machines so the machines themselves are called chunk servers in this context so here here's an example there are multiple multiple chunk servers there is",
    "680-700": " chunks over one two three and four and here's a file one and file one is divided into six chunks in this case C 0 C 1 C 2 C 3 C 4 and C 5 and these chunks as you can see for four of the chunks",
    "700-720": " happen to be on chunks over one one of them is on chunks over two and one of them is on chunks over three now this is not sufficient you actually have restored multiple copies of each of these chunks and so we replicate these chunks so your copies here is a copy of see one on chunks over two a copy of C 2",
    "720-740": " in chunks over 3 and so on so each chunk in this case is replicated twice and if you notice carefully you'll see that the replicas of a chunk are never on the same chunk server they are always on different chunks of so c1 has one replica on chunks over one and one on",
    "740-760": " chunks over 2 C 0 has one and chunks over 1 and 1 and chunks over n and so on and here's here's another file at D D has two chunks d0 and d1 and that's replicated twice and so and so that's",
    "760-780": " stored on different chunk servers as well now so we've subs off a chunk file and stored them on these on these chunk servers now it turns out that the chunk servers also act as compute servers and then whenever your computation has to",
    "780-800": " access data that computation is actually scheduled on the chunk server that actually contains the data this way you avoid moving data to where the computation needs to run but instead you move the computation to where the data is and that's how you sort of avoid and as",
    "800-820": " movement in the system this will become clear when we look at look at some examples so to summarize each file is split into contiguous chunks and the chunks are typically 16 to 64 megabytes in in size and each chunk is replicated in our",
    "820-840": " example we saw each chunk replicated twice but it could be 2x or 3x replication 3x is the most common and we saw that the chunks were actually kept on different chunk servers but when you replicate 3x you know the the system usually makes an effort to keep at least one replica in an entirely different",
    "840-860": " rack if possible and why do we do that we do that because it's you know the most common scenario is that a single node can fail but it's also possible that the switch on a rack can fail and when the switch on Iraq fails the entire rack becomes inaccessible and then if you have all the chunks for you know all",
    "860-880": " the replicas of a chunk in one rack then that whole chunk can become inaccessible so if you keep replicas of a chunk on different racks then even if a switch fails then you can still access that chunk right so the system tries to make sure that that the replicas of a chunk are actually kept on different racks the",
    "880-900": " second component of a distributed file system is a master node now the master node is also known as the it's called the master node and the Google file system it's called the name node in Hadoop HDFS the master node stores metadata about where the files are stored and for example it might you know you'll know",
    "900-920": " that file 1 is divided into 6 chunks and here is here are the locations of each of the 6 chunks and here are the locations of the replicas and the master node itself can be replicated because otherwise it might become a single point of failure the final component of the distributed file system is a client library",
    "920-940": " now when the when a client or an algorithm that needs to access the data tries to access a file it goes through the client library the client library talks to the master and finds the chunk servers that actually store the chunks and once that's done the the client is directly connected to the chunk servers and it can access the data without going",
    "940-960": " through the master nodes so the data access actually happens in a peer-to-peer fashion without going through the master node"
}