{
    "0-20": " So this is really the implementation of how we would do this if everything fits in memory, meaning if we can store graph G in memory and if we can store the parameter beta and the rank vector R in memory. So now, of course, what I have to tell you is I said that we can really take advantage",
    "20-40": " of matrix M being sparse. So what this means is that we want to encode the sparse matrix M using only non-zero entries, and we kind of don't want to store on the disk the zero entries. So the way we do this is to proceed the following. The idea is that basically for every source node, we will store its degree and then just",
    "40-60": " the nodes that this node points to. So in this sense, basically the amount of storage we need is proportional to the number of edges in our graph and not to the number of nodes, which means we can have a huge number of nodes. But all we really need to store is we need to store the links of our graph, and we don't need to store or pay any cost to the links that do not exist in our graph.",
    "60-80": " Since real graphs are sparse, meaning that most of the links in the network don't exist, this way we save a lot of space. So for example, if we are working with our 1 billion node graph and imagine that we have 10 billion edges, then this means we will need around 40 gigabytes to store the links",
    "80-100": " of the graph, and 40 gigabytes is very little in a sense. So far, we assume that everything fits into memory. What for example if matrix M, if our graph is so big that it doesn't fit into a memory",
    "100-120": " of a single machine? Actually, it turns out that even with M matrix not fitting into memory, we can still quite efficiently implement the page rank. So let's make first the following assumption. Let's assume that what we can fit in memory is the vector R. So M is too big to be fit in memory, but R is small enough.",
    "120-140": " So then actually everything is very, very easy and very simple. So the idea is that we will have the R old stored on the disk, and we will have the matrix M stored on the disk. And then the way we will proceed is basically to do one step of power iteration, one step of our page rank method. What we will do is we will basically do the step where we will read from the memory a",
    "140-160": " given node. It's out nodes. We will have the vector R in memory, and we can update its components. So the idea basically is that we keep the new vector R in memory. We keep scanning through the matrix M row by row.",
    "160-180": " We load in a given node and all the nodes it points to. We load its corresponding page rank score, do the multiplication, basically spread this page rank score of our node I into the vector R new. And again, basically what this means is that to do one iteration of this, we need to read",
    "180-200": " a matrix M one time from disk. So the way we can think about this is the following. So at every step, what we need to do is we need to scan the matrix M into the memory, and we have to scan the rank vector R old into memory.",
    "200-220": " So this means that once we have done this, we have to write the R new back to the disk so that the new iteration of our page rank algorithm can start. So if you think about the amount of input output operations we have to do, the amount of input output we have to do is 2 times the size of R plus M. So the size of M, the number",
    "220-240": " of edges. So 2 times R is twice the number of nodes, and the size of the M is the number of edges of the network. So in some sense, every iteration of our algorithm, we need to scan once through the matrix M. Now the question is, can we scale up this even further?",
    "240-260": " Could we take this algorithm and scale it even further in a sense that what if we have so many nodes that not even our vector R fits into memory? Can we still do something? So now we will look how to scale even further up. The idea here is that we will take our vector R and split it into blocks.",
    "260-280": " And now I will just explain the basic idea, and then we will refine this basic idea into something that really works well in practice. So here is how we can think of the problem. Right before, we assumed that our vector R new fits in memory. Now we are assuming that only part of R new fits into memory. So what this means is that we can now compute in one iteration of PageRank of the power",
    "280-300": " method what we do is we load a part of R new into memory, scan through the matrix M, scan through the rank vector R, and compute the correct PageRank scores for a given part of",
    "300-320": " the vector R. And then we would load in the next part of vector R, scan again through the matrix M, scan again through the R old, and update the values here. And then we would load the next block again, scan through M, scan through R, and so on. And this way, we would basically be able to compute all the values of R new in some",
    "320-340": " number of passes over M and over the vector R. However, let's think about how well this works. So the way we think about this is this is very similar to what in databases we call a nested loop join. So the idea is that we take this vector R new and break it into K blocks.",
    "340-360": " And then for every block, we scan matrix M and R old ones. So if you think about how much input-output time or operations we need to do, here is a simple calculation. So basically, we need to do K scans of R and M. So this means that we have K times size of M plus size of R plus we also have to be able",
    "360-380": " to take this R new and write it back to memory or write blocks of it back to memory. So this means we load in K times the matrix M, and we load vector R K plus 1 times.",
    "380-400": " The question is, of course, can we do better? And actually, we can do better. And the trick to do better is to basically preprocess matrix M. So the insight for us to do this is the following. Basically, the matrix M is much bigger than the vector R. So matrix M is, let's say, 20 or 30 times bigger than vector R.",
    "400-420": " So in some sense, we want to avoid reading matrix M into memory multiple times. So we are happy to scan over R, but scanning over M takes lots of time. So what we want to do is we want to preprocess M in some way such that we don't need to load it multiple times. And the way to preprocess M is what is called a block-stripe update algorithm.",
    "420-440": " So what we did is that we took the matrix M, and we preprocessed it into these chunks that correspond actually to the chunks of R new. And the idea is the following. So for every chunk of matrix M, we only store the destination edges that have destinations",
    "440-460": " in the corresponding block of the R new vector. So for example, what this means is that now when we are updating the values of R new in the first block, all we have to do is scan over the first part of the matrix M. And then when we want to update the values R new in the second block, we only need to",
    "460-480": " scan through this part of the matrix M. And then same for the third block, and so on. And what this saves us from is that now we basically, in a single iteration of the power method, all we need to do is we need to do, in some sense, one scan over matrix M. Of course, there is a bit of overhead, because now we have to store the degree of a node",
    "480-500": " multiple times, but that is a relatively small overhead overall. And actually, it's worth making this in practice. So the idea is that we take matrix M and break it into stripes, and each stripe contains only the destination nodes corresponding to the block of the R new, or to the block of",
    "500-520": " nodes in the R new vector. And this, as I mentioned, brings some additional overhead per stripe. But generally, it's very much worth it to have that. And now if we think about what is the input output cost per iteration, we basically see that we need to read the matrix M once, plus there is some epsilon additional cost.",
    "520-540": " And then we need to, as before, read the vector R k times and write it once. So that's why we get k plus 1 times size of R. So let me summarize what we know so far and what we have done. We defined PageRank, and we are able to compute it on kind of arbitrarily large graphs.",
    "540-560": " There are also a few problems with PageRank that we are going to address next. First, PageRank, as defined so far, is a generic measure of an importance of a page. For example, for every node in the graph, we only compute one score. And we don't really say whether a given page is good or important with respect to a given",
    "560-580": " topic. So what we will do next as a solution to this, we will talk about what is called topic specific PageRank. The second thing that is also is that together with PageRank, there are other ways to think about importances of nodes. And one way how to compute importances of nodes in a bit different way is called hubs",
    "580-600": " and authorities. So this is what is also coming. And then the last thing we will discuss is that PageRank is susceptible to what is called link spam. So the idea is that we have spammers on the web who want to manipulate the structure of the web graph such that they boost PageRank score of individual target pages.",
    "600-620": " So the question is, how can we detect spammy web pages on the web? And the solution for this is called TrustRank. So what we'll do next is we will go through each one of these three applications one by one."
}