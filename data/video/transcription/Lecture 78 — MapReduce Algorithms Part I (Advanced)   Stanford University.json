{
    "0-20": " the purpose of this unit is to get you beyond understanding what m produ is to the point where you can use a dupe or a related system effectively I'm going to start with a story about a real problem that came up in a live course I was teaching a while ago it will help us see a common mistake in designing map reduce algorithms and in particular what can be done about it",
    "20-40": " I will then introduce what I think are the two key parameters of a map reduce algorithm called reducer size and replication rate there is an interesting trade-off between them and good design is often a matter of picking the right point for the tradeoff we'll introduce mapping schemas as a way to define problems and get lower bounds on the",
    "40-60": " reducer size as a function of replication rate finally I'm going to drill down on the important problem of matrix multiplication not only can we use the theory to get an optimal reduce algorithm for matrix multiplication but we can extend the theory to a method that uses a Cascade of two map reduced jobs for matrix multiplication and we",
    "60-80": " conclude with the observation that the two job method is in most cases more efficient than the one job method I want to start by reviewing and introducing some notation for describing important components of a map reduce job we need to distinguish between map functions map tasks and mappers and do",
    "80-100": " the same for reduce remember a map reduce job is defined by a map function and a reduced function these are the two pieces of code you have to write to make the job go everything else you do is really setting parameters for Hadoop or another system like",
    "100-120": " it a map task applies the map function to each input in a chunk of the input file and a reduced task applies the reduced function to each of a collection of key value list pairs remember that behind the scenes key value pairs are organized by key and the reduced task is presented with pairs consisting of a key",
    "120-140": " and the list of all the values associated with that key that were generated by any of the map tasks when we talk about the computation cost of map reduce algorithms we need terminology that is more fine grain than tasks so I'm going to use the term mapper to refer to the application of",
    "140-160": " the map function on one input a map task then consists of many mappers so similarly I'll refer to the application of the reduce function to a single key and its Associated list of values as a reducer A reduced task then consists of one or more",
    "160-180": " reducers it is important to observe that it doesn't matter how the mappers are grouped into map tasks nor does it matter how the reducers are grouped into reduce tasks in practice the system with Will Group mappers according to the physical location of their inputs and Will Group reducers into as many reduced tasks as it uses based on some random",
    "180-200": " hash function the important point is that mappers and reducers are the fundamental units of computation during a map reduced job when we run a map reduced job on a public cloud like ec2 we pay for two things rental of processors or compute nodes and the transportation of data",
    "200-220": " across the network different clouds may have different charging schemes but we can still separate the two costs into a comp computation cost of executing the map prism reducers plus the computation done by the system um the system does many things including the management of tasks but",
    "220-240": " the heaviest computation cost associated with the system is the Sorting of key value pairs by key and merging the values with a common key that are generated by different map tasks and then there is the communication cost this is really the cost of moving key value pairs from where they are generated to where they are used by the reducer",
    "240-260": " users in general no communication is needed to move data from the input to the mappers generally it is preferable to move the code to the data rather than vice versa so we assume the map tasks run at the same compute node where they input chunk is located on the other hand we'll assume",
    "260-280": " that every key value pair is consumed by a reducer that is not at the node where it was generated by coincidence the reduced task executed the consuming reducer May execute it the same node where the map task that generated it was executed but this will will be very rare so we'll assume it never occurs to keep",
    "280-300": " the computation simple here are a few important observations that will simplify our calculations of the cost of map reduced jobs okay typically the computation done by the mappers is proportional to the number of key value pairs generated this does not have to be the case since the map function could do",
    "300-320": " something very time consuming and produce very little output but in the common examples of map reduce processing the map function does something simple and its running time is proportional to its output we'll assume the computation cost of the mappers is proportional to the communication cost and it is in fact a small fraction of the communication cost so we'll neglect it or add it to",
    "320-340": " the actual communication cost the system cost can be treated the same way it is principally the cost of organizing the key value pairs in practice a dup sorts by key so you might consider the system cost to be proportional to n log n where n is the number of key value pairs however an",
    "340-360": " external merge sort is in practice linear and ends so we'll assume that either the Sorting time is small compared with the communication cost if n is small enough that a main memory sort is possible or n is so large the sort must be done on disk and then it is proportional to the communication cost",
    "360-380": " and another important point to remember is that on typical Computing clusters communication is often the dominant costs and accounts for the majority of the wall clock time needed to finish the job no matter how many compute nodes we use gigabit Ethernet the typical communication Network sounds fast but in fact it can often fail to keep up when",
    "380-400": " many compute nodes are generating and consuming data on the same network if you're using a service like Amon zc2 you will pay them a certain amount to rent each processor you need and you will also pay them another amount for each gigabyte you move between processors so if you want to",
    "400-420": " minimize cost you need to find the optimum trade-off between computation and communication unfortunately there is a competing desire that may for force your cost to be higher than the minimum possible you want wall clock time to be low which means that you want there to be lots of parallelism",
    "420-440": " available in some cases what happens is that the more parallelism you use the more communication you need if communication is forced to be higher than what would give the minimum dollar cost then you need to trade off your desire to finish Fast against your desire to pay the least amount possible that's a harder",
    "440-460": " trade-off to quantify you have to decide how much finishing fast is worth worth to you here's my attempt at ack picture of what's going on the red line is a hypothetical trade-off between the amount of communication and the amount of computation the total cost is the sum of both costs so we want to find the",
    "460-480": " point in which a 45 Dee line is tangent to the curve and I've suggested that here now here is another hypothetical function that involves wall clock time I've shown the chart as if it were wall clock time versus communic ation cost but technically it is wall clock",
    "480-500": " time against points on the red line the simple case is where you're satisfied with a relatively High time to finish that means you surely satisfied with the wall clock time given by the least cost algorithm okay that is we're",
    "500-520": " here and that corresponds to well should be a straight line but uh but it's not uh that says we would be happy with a an algorithm out here but you can do much better you can you can go right over",
    "520-540": " there but suppose you want the job to finish this fast and you can't that is you can't afford to finish later and you need to pick an algorithm that is on the red line but that has has a higher total",
    "540-560": " cost than the optimum that is you really have to pick this point over here now on the other hand in another scenario you might want to finish this fast but you have in your mind some tradeoff between finishing time and the dollars you have to pay to get the job",
    "560-580": " done in that case you might want to pick a point on the red line like this that has a somewhat higher cost than the op Optimum but it also finishes a little later than you would really like but overall you're as happy as you are going to be with this tradeoff there's a little more to the",
    "580-600": " story of communication and computation trade-off it may be that abstractly you do the same computation at the reducers no matter how you partition the work but if you give one reducer so much input that it has to swap data between main memory and secondary memory then the time to do the same",
    "600-620": " computation can go up radically unfortunately it's also common that if you want a small amount of input per reducer you need to use a lot of communication and we'll see an example like this shortly the consequence is that the communication computation trade-off is really a step function there is one",
    "620-640": " computation cost if the communication is sufficiently high and another larger cost if the communication is too low so here's the same picture of communication computation tradeoff but now the red line is a step function there's still an Optimum point it is the point representing the computation cost",
    "640-660": " assuming everything can be done in main memory and the minimum communication necessary to allow reducers to take that small an amount of data"
}