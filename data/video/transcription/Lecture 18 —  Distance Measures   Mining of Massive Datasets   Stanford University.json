{
    "0-20": " so far except for a few examples we've learned only about how to do lsh for jard similarity using minhing uh there are many other Notions of similarity or distance uh and which one to use depends on what type of data we have and what our notion of similar is uh we're going to begin by studying distance measures",
    "20-40": " in general and see the most useful measures then we'll talk about locality sensitive families of hash functions as a general idea we'll see that it is possible to combine hash functions from a family to get the s-curve effect that we saw for lsh applied to Minash matrices uh in fact the construction is",
    "40-60": " essentially the same for any lsh family and we'll conclude this unit by seeing some particular lsh families and how they work for the cosine distance and ukian distance we'll Begin by introducing the distance measures we need and we start with the formal notion of a distance measure a distance between points in",
    "60-80": " some abstract space is intended to measure closeness or similarity of the points the lower the distance the closer the points and the more similar they are notice that jard similarity is the opposite of what we mean by distance jard similarity is higher for similar sets than for dissimilar sets while a",
    "80-100": " distance measure would have their distance be lower it turns out that one minus the jard similarity is a suitable distance measure to start we see two different kinds of distance measures ukian and non- ukian ukian spaces have dimensions and a real number locates each point along",
    "100-120": " each Dimension the ordinary two or threedimensional ukian spaces are the most common examples but ukian spaces can have any number of dimensions for example a one dimension ukian space is a straight line infinite in both uh directions an important property of idian spaces is that they are dense that",
    "120-140": " is given any two points you can find their average and it and it will be a point in the space we'll see some examples shortly where there is no reasonable notion of the average of points in a space uh that can be a problem in certain s situations uh for for example if you're trying to Cluster points and you want to represent a",
    "140-160": " cluster by a single typical point it's nice to be able to take the average of the points in the cluster but you can't always do that for nonukan spaces there are many Notions of distance between points in ukian Space the best known one is often referred to as the ukian distance where",
    "160-180": " you sum the squares of the distances between the points along each Dimension and then take the square root of the sum however we shall see that there are many different distance measures that also work for an ukian space uh we shall often refer to any of these as a ukian distance",
    "180-200": " so what about other spaces and other distance measures there are many of these as well but a non- ucan distance is based on something other than the location of points in a space a distance measure is a function from pairs of points to some Spa in some space uh to real numbers this this function has to satisfy four important",
    "200-220": " properties first it never has a negative value although the value can be zero but the value of a distance measure can be zero under only one condition that the two points to which it is applied are actually actually the same point uh moreover whenever applied to",
    "220-240": " the same point x as both arguments the value must be zero the distance is symmetric uh that is the distance from X to Y is the same as the distance from y to X and most importantly the function must satisfy the triangle inequality that is the distance from X",
    "240-260": " to Y cannot be greater than the sum of the distance going first from X to some other point Z and then from Z to Y we often see this idea in the observation that one side of a triangle cannot be longer than the sum of the lengths of the other two sides the most common ukian distance is the L2 Norm which is the square root of the sum of the",
    "260-280": " squares of the distances between the two points X and Y measured in each dimension another common choice for ukian distance is the L1 Norm or Manhattan distance if you've ever visited Manhattan in New York uh you know that the streets are laid out in a",
    "280-300": " grid you can't walk directly between points and you need to First Walk In One Direction or Dimension say north south and then in the other direction say East West as a result the L1 Norm between points X and Y is the sum of the distances between X and Y along each uh Dimension and here's an example of two",
    "300-320": " points A and B in the two-dimensional ukian space a is the 55 and B is 98 the difference between a and b in the horizontal Dimension is four and in the vertical Direction it is",
    "320-340": " three thus the L1 normal Manhattan distance between A and B is uh 4 + 3 uh which is 7 on the other hand the L2 Norm is computed as follows we take the square of the distances four and three in each Dimension Square them and sum",
    "340-360": " them that and finally we take the square root since 4 squar is 16 3 squ is 9 the sum is 25 the square root of that is five here's another interesting ukian distance measure called the L Infinity Norm uh here the distance between two two points X and Y is the largest of the",
    "360-380": " distance between X and Y in any of the dimensions of the space in fact we can Define the L subr Norm for any real number R you compute this Norm by taking the sum of the rth powers of the differences of the two points along each of the dimensions and then taking the arth root of the sum",
    "380-400": " notice that this definition is consistent with the definitions we gave for Ral 1 and Ral 2 before and it's also consistent with the notion of an L Infinity Norm because as R gets larger and larger raising numbers to the arth power causes the largest of them to dominate the sum and all other arth powers become negligible then when you",
    "400-420": " take the arth root of the sum you essentially are taking the arth root of the AR Power of the largest which gives you back essentially just the largest of the differences now let's introduce the cast of characters for the non- ukian distances first the jakar distance as we mentioned is just one minus the jard",
    "420-440": " similarity we have to use one minus so identical sets have distance zero and sets with no intersection have distance one which in this case is the greatest possible distance and in this corner the cosine distance uh this distance requires points to be vectors if the vectors have real numbers as components then they are",
    "440-460": " essentially points in a ukian space but the vectors could say have integer components in which case the space is not ukian but either way the cosine distance is the angle between the vectors it's called the cosine distance because as we shall see it is generally easiest to compute",
    "460-480": " the cosine of the angle between the vectors and then use the cosine to figure out the actual angle the edit distance applies to points that are character strings the edit distance between two strings is the minimum number of inserts and deletes needed to transform one of the strings into the other there are some other Notions of",
    "480-500": " edit distance as well for example sometimes we allow a mutation as one edit where a mutation changes one character to another uh for example uh a b c could become uh a DC in one edit without mutations we would have to make",
    "500-520": " two edits to make this change first we would delete the old character B and then second insert uh the the new character D so we would go A to B C to a c and then finally to a d c in Two Steps By the way we're only going to",
    "520-540": " talk about the insert delete version of edit distance in in this course finally consider the Hamming distance it's named after Richard Hamming who happens to be the third winner of the touring award and it applies to points that are bit vectors of the same length the hemming distance",
    "540-560": " between two bit vectors is the number of positions in which they differ here's an example of jard distance uh consider these two sets X and Y their intersection has two members one and three uh and the union has five number",
    "560-580": " members the the numbers 1 through five thus the jard similarity is is two fths but we don't want jard similarity anymore now we want jard distance that's one minus the two- fths giving us a jard distance of 3 fths so let's check the",
    "580-600": " four conditions for a distance measure jakar distance is never less than zero because the jacard similarity can't be greater than one the reason for that is that the size of the intersection of two sets is never greater than the size of their union now uh the distance between a to set X in itself is zero why well X",
    "600-620": " intersect X is the same as X Union X and both are X itself so the jard similarity of a set with itself is one therefore the deard distance is 1 minus one is zero we also have to check that if X is not equal to Y then their jakar distance is strictly greater than zero that is",
    "620-640": " because if X and Y are different then there is at least one element in their Union that's not in their intersection and therefore the intersection is strictly smaller than their Union that means the jard similarity is strictly less than one and the jard distance is strictly greater than zero the Symmetry condition follows from the fact that the union and intersection",
    "640-660": " are both symmetric that is X intersect yal y inter X so both intersections surely have the same size and likewise for the unions the last thing to prove is the triangle inequality uh that's a bit of work but we'll show the proof on the next slide U",
    "660-680": " here's the inequality that says the jard distance from X to Z Plus the jard distance from Z to Y is equal to or greater than the jakar distance from X to Y that is this is the jard similarity of x and z",
    "680-700": " the size of their intersection divided by the size of their Union so this is the jard distance from X to Z and similarly this is the card distance from y to Z and this is the jard distance from X",
    "700-720": " to Y remember we Pro that the jarard similarity between sets A and B is the probability that the Minash values of A and B are the same or put another way this is the probability",
    "720-740": " that the Minh of A and B are different but the probability that Minh of X and Y differ cannot be greater than the probability that the Minash of x and z differ plus the probability that Minash of Y and Z differ by what we saw on the previous slide this claim is equivalent",
    "740-760": " to the triangle in equality okay but the reason is that whenever the Min hash of X and Y are different it is impossible for both Min of x to equal Min of Z and for Minh of Z to equal Min of Y because then by transitivity of equals Minh of X would equal Minh of",
    "760-780": " Y so in terms of end diagrams let the plane represent triples of sets X Y and Z here are those triples where Min hash values of x and z differ and here are the triples where the Min hashes of Y and Z differ and contained within their Union must be the set of triples where X and Y",
    "780-800": " have different Minh values another important distance measure is the cosine distance okay this distance is useful for data that is in the form of a vector uh often the vector is in very high Dimensions uh for example documents are often viewed as the vector of counts of each of the words appearing in the",
    "800-820": " document so each word is a dimension now to define the cosine distance think of a data point as a vector from the origin in some space to the point in question uh any two points have an angle formed at their origin between their vectors okay you have something like",
    "820-840": " this we can compute the cosine of this angle from the components of the two vectors to do so we take the dotproduct of the vectors the dot product is the sum of the products of the corresponding components and then we divide by the lengths of the two vectors the length of a vector from the origin",
    "840-860": " is actually the normal ukian distance what we call the L2 Norm of the point at the head of the vector to the origin that is it is the square root of the sum of the squares of the components of the vector for example here are two vectors P1 and",
    "860-880": " P2 the dot product of the vectors is two uh the products of each of the first three components is zero the is 0 * 1 is 0 0 * 0 is 0 1 * 0 is also zero but in the last two components each Vector is one uh so the dot product is the sum of",
    "880-900": " 1 * 1 + 1 * 1 and that's two uh for the lengths of the vector P1 has three ones so we sum three 1 squared and then take the square root giving us the square root of three uh P2 also has three ones and two two zeros as components so its length is",
    "900-920": " the same square < T of three thus the cosine of the angle between P1 and P2 is two the dot product that is divided by the product of the two Vector lengths each of those lengths is the square root of three so their product is three and the cosine of the angle is 2/3 if you look that up in a table of cosiness you'll find that this",
    "920-940": " angle is about 48\u00b0 so here's a diagram with the two vectors P1 and P2 shown in the plane that passes through them no matter how many dimensions the vectors have any two lines that intersect and and P1 and P2 do intersect at the origin they'll form a plane I'm not going to do the math but if you project P1 on to P2 as we've done",
    "940-960": " here the length of the projection is the dot product divided by the length of P2 then the cosine of the angle between them is the ratio of adjacent over hypotenuse uh which is the dot product divided by P2 that's the",
    "960-980": " adjacent and then divided by the length of P1 that's of course the hypotenuse uh let's see why the cosine distance satisfies the axioms of a distance first remember that vectors here are really directions not magnitudes so two vectors with the same direction and different magnitudes are really the same Vector even a vector and",
    "980-1000": " its negation the reverse of the vector are to be thought of as the same Vector uh for first the distance between a Vector in itself is zero the angle of vector makes with itself is 0 de uh moreover the angle of a vector with any different Vector is not 0 degrees so no",
    "1000-1020": " pair of different vectors have a distance of zero again remember we think of vectors as Direction only otherwise you could have say a vector and twice that Vector being quote different and yet having a zero angle between them to make sure that all distances are non- negative we shall interpret all angles as in the range 0 to",
    "1020-1040": " 180\u00b0 uh notice that any two vectors from the origin will make an angle between 0 and 180 de in the plane they Define the rest of the argument is by physical reasoning symmetry simply says that the angle from Vector to X rotating to Y is the same as the angle from y",
    "1040-1060": " rotating to X and the triangle inequality is merely the observation that if we rotate from X to Z and then from Z to Y the total rotation can't be less than what we get if we rotate from X to Y directly now consider the edit distance recall this distance measure assumes points or character strings and",
    "1060-1080": " the edit distance from X to Y is the minimum number of inserts and deletes needed to turn X into y there is an equivalent formula for edit distance based on the notion of a longest common subsequence of two strings X and Y uh the LCS of X and Y is the longest string that is a subsequence",
    "1080-1100": " of both we say one string is a subsequence of another if we can get the first by deleting zero or more positions from the second note that the positions of the deleted characters do not have to be consecutive we'll give an example on the next slide to make these ideas clear the",
    "1100-1120": " formula for the edit distance in terms of the LCS is this it's the sum of the lengths of the two strings length of X length of Y minus twice the length of the LCS here's an example where we'll compute the edit distance of these two strings X and Y in",
    "1120-1140": " two different ways first we can turn X into y by uh deleting a and then inserting u and [Music] v after the D that uses three edits and it's it's easy to check that there's no way to get from X to Y using fewer edits",
    "1140-1160": " thus the edit distance is three uh notice that we can get from y to X by doing the same edits in reverse that is we delete u and v and then we insert a to get X in",
    "1160-1180": " general a pair of strings can have several different lcss of the same length in this case there's only one bcde e it is obtained from X by deleting the first position containing a and it is obtained from y by deleting the fourth and fifth",
    "1180-1200": " positions uh containing u and v and to verify that the formula relating at a distance to the LCS holds in this case the sum of the lengths of the two strings is 5 + 6 or 11 and the LCS has a length of four but 11 - t four is three which is indeed the edit",
    "1200-1220": " distance we can check that edit distance also satisfies the requirements to be considered a distance measure uh first of all the edit distance from the string X to itself is surely zero because zero edits suffice moreover If X and Y are different at least one edit is required to change one to the other so no distances are other no other distances",
    "1220-1240": " are zero and there's no way for there to be a negative number of edit so surely there are no negative edit distances symmetry holds because given any sequence of inserts and deletes say taking string X to string y we can reverse that sequence and replace the deletion of a character C by the insertion of c and replace the insertion",
    "1240-1260": " of C by a deletion we saw an example of this transformation on the previous slide and the triangle inequality holds for the following reason one way to transform X to Y is first to transform X to Z and then Z to y the minimum number of edits needed to make those",
    "1260-1280": " Transformations is the sum of the edit distances from X to Z and from Z to Y but this sequence of edits is one of the possible ways to transform X to Y so the total number of edits is at least the edit distance from X to Y and next on our list is the Hamming distance recall the Hamming distance is the number of positions in which two bit vectors of",
    "1280-1300": " the same length differ so for example the hemming distance between P1 and P2 is two because they differ in the third and fourth positions that is here there's one zero there there 01 other than that there they are the same the argument",
    "1300-1320": " about why Hamming distance is also a distance measure is quite the same as what we've seen before the Hamming distance between a string and itself is zero because surely the string the string differs in zero uh positions on the other hand the Hamming distance between different strings cannot be zero because they differ in at least one",
    "1320-1340": " position there can't be a negative Hamming distance because you can't talk about strings differing in a negative number of positions symmetry of Hamming distance follows from the notion that the relationship different from on bits is symmetric that is a is different from B if and only if B is different from a and the triangle inequality argument is very",
    "1340-1360": " much like what we saw for for edit distance one way to change bit string X to Y by flipping bits is first to flip bits to turn X to Z and then flip bits to turn Z to Y the sum of these two numbers of flips cannot be less than the number of bits you have to flip to turn X to Y directly"
}